{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09f80375",
   "metadata": {},
   "source": [
    "## NLP Pierwsze kody. Tokeny, steaming i lemmatyzacja. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdea2cf1",
   "metadata": {},
   "source": [
    "Liczenie słów. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f87d95",
   "metadata": {},
   "source": [
    " ##   Liczenie słów funkcja Counter (wielkość liter ma znaczenie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d618b6c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Idziemy': 2,\n",
       "         'sobie': 1,\n",
       "         'na': 1,\n",
       "         'wycieczkę.': 1,\n",
       "         'Wycieczkę': 1,\n",
       "         'z': 1,\n",
       "         'psem.': 1})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter (\"Idziemy sobie na wycieczkę. Wycieczkę z psem. Idziemy\".split())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314f40cb-d2a7-4476-bf9a-1e3b08cabc2b",
   "metadata": {},
   "source": [
    "# użycie  spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291edc71-69bb-4dbd-9202-8fbab71de78d",
   "metadata": {},
   "source": [
    "# Kod do zapisu tokenów, pos i lemmitazacji. Zapisuje pliki wyniki_lemma.csv, oraz lemmas_2 z kolumnami 'orth_', 'lemma_', 'tag_', 'pos_', 'dep_. Dodatkowo wyodrębnia nazwy i imiona w pliku.\n",
    "\n",
    "\n",
    "here is a simple Python code that demonstrates the basics of natural language processing (NLP), including tokenization, stemming, and lemmatization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fd14556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      "Warszawa\n",
      "to\n",
      "dla\n",
      "mnie\n",
      "galerie\n",
      ",\n",
      "muzea\n",
      ",\n",
      "ludzie\n",
      ",\n",
      "energia\n",
      ",\n",
      "ale\n",
      "też\n",
      "hałas\n",
      ",\n",
      "tłok\n",
      ",\n",
      "korki\n",
      ".\n",
      "Nie\n",
      "jest\n",
      "tu\n",
      "może\n",
      "jak\n",
      "w\n",
      "Berlinie\n",
      ",\n",
      "ale\n",
      "lepiej\n",
      "niż\n",
      "w\n",
      "Gdańsku\n",
      ".\n",
      "Podoba\n",
      "mi\n",
      "się\n",
      ",\n",
      "że\n",
      "ludzie\n",
      "próbują\n",
      "zmieniać\n",
      "to\n",
      "miasto\n",
      ",\n",
      "organizują\n",
      "się\n",
      "sąsiedzi\n",
      ",\n",
      "społeczności\n",
      ".\n",
      "Jest\n",
      "to\n",
      "Babilon\n",
      ",\n",
      "ale\n",
      "jednak\n",
      "uczy\n",
      "funkcjonowania\n",
      "z\n",
      "innymi\n",
      ".\n",
      "Warszawa Warszawa SUBST\n",
      "to to PRED\n",
      "dla dla PREP\n",
      "mnie ja PPRON12\n",
      "galerie galeria _SP\n",
      ", , INTERP\n",
      "muzea muzea SUBST\n",
      ", , INTERP\n",
      "ludzie człowiek SUBST\n",
      ", , INTERP\n",
      "energia energia SUBST\n",
      ", , INTERP\n",
      "ale ale CONJ\n",
      "też też QUB\n",
      "hałas hałas _SP\n",
      ", , INTERP\n",
      "tłok tłok SUBST\n",
      ", , INTERP\n",
      "korki korek SUBST\n",
      ". . INTERP\n",
      "Nie nie QUB\n",
      "jest być FIN\n",
      "tu tu ADV\n",
      "może móc QUB\n",
      "jak jak ADV\n",
      "w w PREP\n",
      "Berlinie Berlin SUBST\n",
      ", , INTERP\n",
      "ale ale CONJ\n",
      "lepiej dobrze ADV\n",
      "niż niż CONJ\n",
      "w w PREP\n",
      "Gdańsku Gdańsk _SP\n",
      ". . INTERP\n",
      "Podoba podobać FIN\n",
      "mi ja PPRON12\n",
      "się się QUB\n",
      ", , INTERP\n",
      "że że COMP\n",
      "ludzie człowiek SUBST\n",
      "próbują próbować FIN\n",
      "zmieniać zmieniać INF\n",
      "to ten ADJ\n",
      "miasto miasto SUBST\n",
      ", , INTERP\n",
      "organizują organizować FIN\n",
      "się się QUB\n",
      "sąsiedzi sąsiad _SP\n",
      ", , INTERP\n",
      "społeczności społeczność _SP\n",
      ". . INTERP\n",
      "Jest być FIN\n",
      "to to PRED\n",
      "Babilon Babilon SUBST\n",
      ", , INTERP\n",
      "ale ale CONJ\n",
      "jednak jednak CONJ\n",
      "uczy uczyć FIN\n",
      "funkcjonowania funkcjonowanie GER\n",
      "z z PREP\n",
      "innymi inny ADJ\n",
      ". . INTERP\n",
      "Lemma counts:\n",
      "Warszawa 1\n",
      "to 2\n",
      "dla 1\n",
      "ja 2\n",
      "galeria 1\n",
      ", 11\n",
      "muzea 1\n",
      "człowiek 2\n",
      "energia 1\n",
      "ale 3\n",
      "też 1\n",
      "hałas 1\n",
      "tłok 1\n",
      "korek 1\n",
      ". 4\n",
      "nie 1\n",
      "być 2\n",
      "tu 1\n",
      "móc 1\n",
      "jak 1\n",
      "w 2\n",
      "Berlin 1\n",
      "dobrze 1\n",
      "niż 1\n",
      "Gdańsk 1\n",
      "podobać 1\n",
      "się 2\n",
      "że 1\n",
      "próbować 1\n",
      "zmieniać 1\n",
      "ten 1\n",
      "miasto 1\n",
      "organizować 1\n",
      "sąsiad 1\n",
      "społeczność 1\n",
      "Babilon 1\n",
      "jednak 1\n",
      "uczyć 1\n",
      "funkcjonowanie 1\n",
      "z 1\n",
      "inny 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Warszawa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">placeName</span>\n",
       "</mark>\n",
       " to dla mnie galerie, muzea, ludzie, energia, ale też hałas, tłok, korki. Nie jest tu może jak w \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Berlinie\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">placeName</span>\n",
       "</mark>\n",
       ", ale lepiej niż w \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gdańsku\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">placeName</span>\n",
       "</mark>\n",
       ". Podoba mi się, że ludzie próbują zmieniać to miasto, organizują się sąsiedzi, społeczności. Jest to \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Babilon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">persName</span>\n",
       "</mark>\n",
       ", ale jednak uczy funkcjonowania z innymi. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "\n",
    "# Load the Polish language model\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "\n",
    "# Define a sample text\n",
    "text = \"Warszawa to dla mnie galerie, muzea, ludzie, energia, ale też hałas, tłok, korki. Nie jest tu może jak w Berlinie, ale lepiej niż w Gdańsku. Podoba mi się, że ludzie próbują zmieniać to miasto, organizują się sąsiedzi, społeczności. Jest to Babilon, ale jednak uczy funkcjonowania z innymi. \"\n",
    "\n",
    "# Tokenize the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the tokens\n",
    "print(\"Tokens:\")\n",
    "for token in doc:\n",
    "    print(token.text)\n",
    "\n",
    "\n",
    "# Lemmatize the tokens\n",
    "for token in doc:\n",
    "     print(token.text, token.lemma_, token.tag_)\n",
    "\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "lemma_counts = Counter(lemmas)\n",
    "\n",
    "# Print the lemma counts\n",
    "print(\"Lemma counts:\")\n",
    "for lemma, count in lemma_counts.items():\n",
    "    print(lemma, count)\n",
    "    \n",
    "with open(\"wyniki_lemma.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"lemma\", \"count\"])\n",
    "    for lemma, count in lemma_counts.items():\n",
    "        writer.writerow([lemma, count])\n",
    "    \n",
    "attribs = ['orth_', 'lemma_', 'tag_', 'pos_', 'dep_', 'head']\n",
    "table = [{att:tok.__getattribute__(att) for att in attribs} for tok in doc]\n",
    "# Create a DataFrame from the extracted attributes\n",
    "df = pd.DataFrame(table)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(\"lemmas_2.csv\")\n",
    "displacy.render(doc, style=\"ent\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f0de27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ba107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      "Warszawa\n",
      "galerie\n",
      "muzea\n",
      "ludzie\n",
      "energia\n",
      "hałas\n",
      "tłok\n",
      "korki\n",
      "Berlinie\n",
      "lepiej\n",
      "Gdańsku\n",
      "Podoba\n",
      "ludzie\n",
      "próbują\n",
      "zmieniać\n",
      "miasto\n",
      "organizują\n",
      "sąsiedzi\n",
      "społeczności\n",
      "Babilon\n",
      "uczy\n",
      "funkcjonowania\n",
      "innymi\n",
      "Warszawa Warszawa SUBST\n",
      "to to PRED\n",
      "dla dla PREP\n",
      "mnie ja PPRON12\n",
      "galerie galeria _SP\n",
      ", , INTERP\n",
      "muzea muzea SUBST\n",
      ", , INTERP\n",
      "ludzie człowiek SUBST\n",
      ", , INTERP\n",
      "energia energia SUBST\n",
      ", , INTERP\n",
      "ale ale CONJ\n",
      "też też QUB\n",
      "hałas hałas _SP\n",
      ", , INTERP\n",
      "tłok tłok SUBST\n",
      ", , INTERP\n",
      "korki korek SUBST\n",
      ". . INTERP\n",
      "Nie nie QUB\n",
      "jest być FIN\n",
      "tu tu ADV\n",
      "może móc QUB\n",
      "jak jak ADV\n",
      "w w PREP\n",
      "Berlinie Berlin SUBST\n",
      ", , INTERP\n",
      "ale ale CONJ\n",
      "lepiej dobrze ADV\n",
      "niż niż CONJ\n",
      "w w PREP\n",
      "Gdańsku Gdańsk _SP\n",
      ". . INTERP\n",
      "Podoba podobać FIN\n",
      "mi ja PPRON12\n",
      "się się QUB\n",
      ", , INTERP\n",
      "że że COMP\n",
      "ludzie człowiek SUBST\n",
      "próbują próbować FIN\n",
      "zmieniać zmieniać INF\n",
      "to ten ADJ\n",
      "miasto miasto SUBST\n",
      ", , INTERP\n",
      "organizują organizować FIN\n",
      "się się QUB\n",
      "sąsiedzi sąsiad _SP\n",
      ", , INTERP\n",
      "społeczności społeczność _SP\n",
      ". . INTERP\n",
      "Jest być FIN\n",
      "to to PRED\n",
      "Babilon Babilon SUBST\n",
      ", , INTERP\n",
      "ale ale CONJ\n",
      "jednak jednak CONJ\n",
      "uczy uczyć FIN\n",
      "funkcjonowania funkcjonowanie GER\n",
      "z z PREP\n",
      "innymi inny ADJ\n",
      ". . INTERP\n",
      "Lemma counts:\n",
      "Warszawa 1\n",
      "to 2\n",
      "dla 1\n",
      "ja 2\n",
      "galeria 1\n",
      ", 11\n",
      "muzea 1\n",
      "człowiek 2\n",
      "energia 1\n",
      "ale 3\n",
      "też 1\n",
      "hałas 1\n",
      "tłok 1\n",
      "korek 1\n",
      ". 4\n",
      "nie 1\n",
      "być 2\n",
      "tu 1\n",
      "móc 1\n",
      "jak 1\n",
      "w 2\n",
      "Berlin 1\n",
      "dobrze 1\n",
      "niż 1\n",
      "Gdańsk 1\n",
      "podobać 1\n",
      "się 2\n",
      "że 1\n",
      "próbować 1\n",
      "zmieniać 1\n",
      "ten 1\n",
      "miasto 1\n",
      "organizować 1\n",
      "sąsiad 1\n",
      "społeczność 1\n",
      "Babilon 1\n",
      "jednak 1\n",
      "uczyć 1\n",
      "funkcjonowanie 1\n",
      "z 1\n",
      "inny 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Warszawa\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">placeName</span>\n",
       "</mark>\n",
       " to dla mnie galerie, muzea, ludzie, energia, ale też hałas, tłok, korki. Nie jest tu może jak w \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Berlinie\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">placeName</span>\n",
       "</mark>\n",
       ", ale lepiej niż w \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Gdańsku\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">placeName</span>\n",
       "</mark>\n",
       ". Podoba mi się, że ludzie próbują zmieniać to miasto, organizują się sąsiedzi, społeczności. Jest to \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Babilon\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">persName</span>\n",
       "</mark>\n",
       ", ale jednak uczy funkcjonowania z innymi. </div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import csv\n",
    "\n",
    "# Load the Polish language model\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "\n",
    "# Define a sample text\n",
    "text = \"Warszawa to dla mnie galerie, muzea, ludzie, energia, ale też hałas, tłok, korki. Nie jest tu może jak w Berlinie, ale lepiej niż w Gdańsku. Podoba mi się, że ludzie próbują zmieniać to miasto, organizują się sąsiedzi, społeczności. Jest to Babilon, ale jednak uczy funkcjonowania z innymi. \"\n",
    "\n",
    "# Tokenize the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print the tokens\n",
    "print(\"Tokens:\")\n",
    "for token in doc:\n",
    "    # Check if the token is not a stop word and is not a comma\n",
    "    if not token.is_stop and not token.text == \",\"and not token.text == \".\":\n",
    "        print(token.text)\n",
    "\n",
    "# Lemmatize the tokens\n",
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.tag_)\n",
    "\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "lemma_counts = Counter(lemmas)\n",
    "\n",
    "# Print the lemma counts\n",
    "print(\"Lemma counts:\")\n",
    "for lemma, count in lemma_counts.items():\n",
    "    print(lemma, count)\n",
    "\n",
    "# Write the lemma counts to a CSV file\n",
    "with open(\"lemma_counts.csv\", \"w\", newline=\"\") as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\"lemma\", \"count\"])\n",
    "    for lemma, count in lemma_counts.items():\n",
    "        writer.writerow([lemma, count])\n",
    "\n",
    "# Extract attributes of the tokens\n",
    "attribs = ['orth_', 'lemma_', 'tag_', 'pos_', 'dep_', 'head']\n",
    "table = [{att:tok.__getattribute__(att) for att in attribs} for tok in doc]\n",
    "\n",
    "# Create a DataFrame from the extracted attributes\n",
    "df = pd.DataFrame(table)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "df.to_csv(\"lemmas.csv\")\n",
    "\n",
    "# Visualize the dependencies in the text\n",
    "displacy.render(doc, style=\"ent\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d172ca59",
   "metadata": {},
   "source": [
    "## Kod, który pokazuje lemmy i nazwy pos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c97676",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Load the Polish language model\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "\n",
    "# Define a dictionary of POS tag definitions\n",
    "pos_tag_definitions = {\n",
    "    \"ADJ\": \"adjective\",\n",
    "    \"ADV\": \"adverb\",\n",
    "    \"INTJ\": \"interjection\",\n",
    "    \"NOUN\": \"noun\",\n",
    "    \"VERB\": \"verb\",\n",
    "}\n",
    "\n",
    "# Define a sample text\n",
    "text = \"Warszawa to dla mnie galerie, muzea, ludzie, energia, ale też hałas, tłok, korki. Nie jest tu może jak w Berlinie, ale lepiej niż w Gdańsku. Podoba mi się, że ludzie próbują zmieniać to miasto, organizują się sąsiedzi, społeczności. Jest to Babilon, ale jednak uczy funkcjonowania z innymi. \"\n",
    "\n",
    "# Tokenize the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Lemmatize the tokens\n",
    "lemmas = [token.lemma_ for token in doc]\n",
    "\n",
    "# Count the frequencies of lemmas\n",
    "lemma_counts = Counter(lemmas)\n",
    "\n",
    "# Sort the lemma counts by frequency\n",
    "sorted_lemma_counts = sorted(lemma_counts.items(), key=lambda item: int(item[1]), reverse=True)\n",
    "\n",
    "# Create a list of tuples with lemma, count, and POS tag\n",
    "lemma_counts_with_pos = []\n",
    "for lemma, count in sorted_lemma_counts:\n",
    "    for token in doc:\n",
    "        if token.lemma_ == lemma:\n",
    "            pos_tag = token.pos_\n",
    "            pos_tag_definition = spacy.explain(pos_tag) or \"N/A\"\n",
    "            lemma_counts_with_pos.append((lemma, count, pos_tag, pos_tag_definition))\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# Create a DataFrame from the list of tuples\n",
    "df = pd.DataFrame(lemma_counts_with_pos, columns=[\"lemma\", \"count\", \"pos\", \"pos_definition\"])\n",
    "\n",
    "# Translate the column names to Polish\n",
    "df = df.rename(columns={\n",
    "    \"lemma\": \"lemma\",\n",
    "    \"count\": \"liczba\",\n",
    "    \"pos\": \"część mowy\",\n",
    "    \"pos_definition\": \"definicja części mowy\"\n",
    "})\n",
    "\n",
    "# Translate the POS tag definitions to Polish\n",
    "translations = {\n",
    "    \"ADJ\": \"przymiotnik\",\n",
    "    \"ADP\": \"przyimek\",\n",
    "    \"ADV\": \"przysłówek\",\n",
    "    \"AUX\": \"czasownik pomocniczy\",\n",
    "    \"CCONJ\": \"spójnik koordynujący\",\n",
    "    \"DET\": \"przedimek\",\n",
    "    \"INTJ\": \"wykrzyknik\",\n",
    "    \"NOUN\": \"rzeczownik\",\n",
    "    \"NUM\": \"liczebnik\",\n",
    "    \"PART\": \"cząstka\",\n",
    "    \"PRON\": \"zaimek\",\n",
    "    \"PROPN\": \"nazwa własna\",\n",
    "    \"PUNCT\": \"interpunkcja\",\n",
    "    \"SCONJ\": \"spójnik podporządkowujący\",\n",
    "    \"SYM\": \"symbol\",\n",
    "    \"VERB\": \"czasownik\",\n",
    "    \"X\": \"inny\"\n",
    "}\n",
    "df[\"części mowy (tłumaczenie)\"] = df[\"część mowy\"].map(translations)\n",
    "\n",
    "# Print the DataFrame as a table\n",
    "print(df)\n",
    "df.to_csv(\"lemmas_z_nazwami.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acce3a7",
   "metadata": {},
   "source": [
    "##  - NLP pokazanie relacji w zdaniu. \n",
    "In natural language processing, the nsubj and nmod labels are part of the Universal Dependencies (UD) scheme, which is a standardized set of syntactic dependency \n",
    "The nsubj label indicates that the word with this label is the nominal subject of the sentence, while the nmod label indicates that the word with this label is a nominal modifier of the sentence.\n",
    "This code uses the spacy library to load a Polish language model and tokenize a given sample text.\n",
    "It then uses the displacy module to render a dependency parse of the tokenized text, which shows the syntactic dependencies between the words in the text. \n",
    "This can be useful for analyzing the structure of a sentence and understanding the roles that each word plays in the sentence. \n",
    "In this case, the dependency parse can help you understand how the words in the sample text relate to each other syntactically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4fd4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "#import pandas as pd\n",
    "from spacy import displacy\n",
    "#from collections import Counter\n",
    "import csv\n",
    "\n",
    "\n",
    "# Load the Polish language model\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "\n",
    "# Define a sample text\n",
    "text = \"Warszawa to dla mnie galerie, muzea, ludzie, energia, ale też hałas, tłok, korki. Nie jest tu może jak w Berlinie, ale lepiej niż w Gdańsku. Podoba mi się, że ludzie próbują zmieniać to miasto, organizują się sąsiedzi, społeczności. Jest to Babilon, ale jednak uczy funkcjonowania z innymi. \"\n",
    "\n",
    "# Tokenize the text\n",
    "doc = nlp(text)\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf199d9",
   "metadata": {},
   "source": [
    "##Kolory - nie działa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2d6409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import csv\n",
    "#define sytax definitions\n",
    "syntax_defs = {\n",
    "    \"dep\": {\n",
    "        \"nmod\": {\"color\": \"blue\"},\n",
    "        \"NOUN\": {\"color\": \"red\"},\n",
    "        \"punct\": {\"color\": \"black\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "# Load the Polish language model\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "\n",
    "# Define a sample text\n",
    "text = \"Warszawa to dla mnie galerie, muzea, ludzie, energia, ale też hałas, tłok, korki. Nie jest tu może jak w Berlinie, ale lepiej niż w Gdańsku. Podoba mi się, że ludzie próbują zmieniać to miasto, organizują się sąsiedzi, społeczności. Jest to Babilon, ale jednak uczy funkcjonowania z innymi. \"\n",
    "\n",
    "# Tokenize the text\n",
    "doc = nlp(text)\n",
    "\n",
    "displacy.render(doc, style=\"dep\", options=syntax_defs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36a4164",
   "metadata": {},
   "source": [
    "## Syntatyczne zależności dla zdań. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45e3c2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Warszawa to dla mnie galerie, muzea, ludzie, energia, ale też hałas, tłok, korki.\n",
      "Dependency parse:\n",
      "Warszawa\tnsubj\n",
      "to\tcop\n",
      "dla\tcase\n",
      "mnie\tnmod\n",
      "galerie\tROOT\n",
      ",\tpunct\n",
      "muzea\tconj\n",
      ",\tpunct\n",
      "ludzie\tconj\n",
      ",\tpunct\n",
      "energia\tconj\n",
      ",\tpunct\n",
      "ale\tcc\n",
      "też\tadvmod:emph\n",
      "hałas\tconj\n",
      ",\tpunct\n",
      "tłok\tconj\n",
      ",\tpunct\n",
      "korki\tconj\n",
      ".\tpunct\n",
      "\n",
      "Sentence: Nie jest tu może jak w Berlinie, ale lepiej niż w Gdańsku.\n",
      "Dependency parse:\n",
      "Nie\tadvmod:neg\n",
      "jest\taux\n",
      "tu\tadvmod\n",
      "może\tROOT\n",
      "jak\tmark\n",
      "w\tcase\n",
      "Berlinie\tobl:cmpr\n",
      ",\tpunct\n",
      "ale\tcc\n",
      "lepiej\tconj\n",
      "niż\tmark\n",
      "w\tcase\n",
      "Gdańsku\tobl:cmpr\n",
      ".\tpunct\n",
      "\n",
      "Sentence: Podoba mi się, że ludzie próbują zmieniać to miasto, organizują się sąsiedzi, społeczności.\n",
      "Dependency parse:\n",
      "Podoba\tROOT\n",
      "mi\tiobj\n",
      "się\texpl:pv\n",
      ",\tpunct\n",
      "że\tmark\n",
      "ludzie\tnsubj\n",
      "próbują\tcsubj\n",
      "zmieniać\txcomp\n",
      "to\tdet\n",
      "miasto\tobj\n",
      ",\tpunct\n",
      "organizują\tconj\n",
      "się\texpl:pv\n",
      "sąsiedzi\tnsubj\n",
      ",\tpunct\n",
      "społeczności\tconj\n",
      ".\tpunct\n",
      "\n",
      "Sentence: Jest to Babilon, ale jednak uczy funkcjonowania z innymi.\n",
      "Dependency parse:\n",
      "Jest\taux\n",
      "to\tcop\n",
      "Babilon\tROOT\n",
      ",\tpunct\n",
      "ale\tcc\n",
      "jednak\tadvmod:emph\n",
      "uczy\tconj\n",
      "funkcjonowania\tobj\n",
      "z\tcase\n",
      "innymi\tnmod\n",
      ".\tpunct\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the Polish language model\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "\n",
    "# Define a sample text\n",
    "text = \"Warszawa to dla mnie galerie, muzea, ludzie, energia, ale też hałas, tłok, korki. Nie jest tu może jak w Berlinie, ale lepiej niż w Gdańsku. Podoba mi się, że ludzie próbują zmieniać to miasto, organizują się sąsiedzi, społeczności. Jest to Babilon, ale jednak uczy funkcjonowania z innymi. \"\n",
    "\n",
    "# Tokenize the text and split it into sentences\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the sentences and print the dependency parse for each sentence\n",
    "for sent in doc.sents:\n",
    "    print(\"Sentence:\", sent.text)\n",
    "    print(\"Dependency parse:\")\n",
    "    for token in sent:\n",
    "        print(f\"{token.text}\\t{token.dep_}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3127a593",
   "metadata": {},
   "source": [
    "## Tłumaczenia dla Universal Dependencies 2. niversal Dependencies (UD) is a framework for consistent annotation of grammar (parts of speech, morphological features, and syntactic dependencies) across different human languages. Tylko wyświetlanie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35865000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import csv\n",
    "\n",
    "# Load the Polish language model\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "\n",
    "# Define a sample text\n",
    "text = \"Warszawa to dla mnie galerie, muzea, ludzie, energia, ale też hałas, tłok, korki. Nie jest tu może jak w Berlinie, ale lepiej niż w Gdańsku. Podoba mi się, że ludzie próbują zmieniać to miasto, organizują się sąsiedzi, społeczności. Jest to Babilon, ale jednak uczy funkcjonowania z innymi. \"\n",
    "\n",
    "# Define a dictionary that maps English dependency labels to Polish translations\n",
    "dep_labels = {\n",
    "    \"nsubj\": \"podmiot\",\n",
    "    \"nmod\": \"mianownikowy modyfikator\",\n",
    "    \"ROOT\": \"rzeczownik\",\n",
    "    \"punct\": \"interpunkcja\",\n",
    "    \"advmod\": \"modyfikator adverbialny\",\n",
    "    \"cc\": \"spójnik\",\n",
    "    \"conj\": \"koniunkcja\",\n",
    "    \"det\": \"determinator\",\n",
    "    \"dobj\": \"orzeczenie\",\n",
    "    \"aux\": \"czasownik\",\n",
    "    \"cop\": \"kopula\",\n",
    "    \"case\": \"przypadek\",\n",
    "    \"advmod:emph\": \"modyfikator adverbialny z podkreśleniem\",\n",
    "    \"advmod:neg\": \"modyfikator adverbialny negujący\",\n",
    "    \"obl\": \"mianownikowy modyfikator obliczeniowy\",\n",
    "    \"mark\": \"znacznik\",\n",
    "    \"obl:cmpr\": \"mianownikowy modyfikator porównawczy\",\n",
    "    \"iobj\": \"\",\n",
    "    \"expl:pv\": \"\",\n",
    "    \"csubj\": \"\",\n",
    "    \"xcomp\":\"\",\n",
    "    \"obj\":\"\",\n",
    "}\n",
    "\n",
    "# Tokenize the text and split it into sentences\n",
    "doc = nlp(text)\n",
    "\n",
    "\n",
    "# Iterate over the sentences and print the dependency parse for each sentence\n",
    "for sent in doc.sents:\n",
    "    print(\"Sentence:\", sent.text)\n",
    "    print(\"Dependency parse:\")\n",
    "    for token in sent:\n",
    "        # Look up the Polish translation of the dependency label and print it\n",
    "        # along with the token and the English label\n",
    "        print(f\"{token.text}\\t{dep_labels[token.dep_]}\\t{token.dep_}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3adf2f4",
   "metadata": {},
   "source": [
    "## Zapis do pliku relacje_syntatyczne.csv z polskim tłumaczeniem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61827e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import csv\n",
    "\n",
    "# Load the Polish language model\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "\n",
    "# Define a sample text\n",
    "text = \"Warszawa to dla mnie galerie, muzea, ludzie, energia, ale też hałas, tłok, korki. Nie jest tu może jak w Berlinie, ale lepiej niż w Gdańsku. Podoba mi się, że ludzie próbują zmieniać to miasto, organizują się sąsiedzi, społeczności. Jest to Babilon, ale jednak uczy funkcjonowania z innymi. \"\n",
    "\n",
    "# Define a dictionary that maps English dependency labels to Polish translations\n",
    "dep_labels = {\n",
    "    \"nsubj\": \"podmiot\",\n",
    "    \"nmod\": \"mianownikowy modyfikator\",\n",
    "    \"ROOT\": \"rzeczownik\",\n",
    "    \"punct\": \"interpunkcja\",\n",
    "    \"advmod\": \"modyfikator adverbialny\",\n",
    "    \"cc\": \"spójnik\",\n",
    "    \"conj\": \"koniunkcja\",\n",
    "    \"det\": \"determinator\",\n",
    "    \"dobj\": \"orzeczenie\",\n",
    "    \"aux\": \"czasownik\",\n",
    "    \"cop\": \"kopula\",\n",
    "    \"case\": \"przypadek\",\n",
    "    \"advmod:emph\": \"modyfikator adverbialny z podkreśleniem\",\n",
    "    \"advmod:neg\": \"modyfikator adverbialny negujący\",\n",
    "    \"obl\": \"mianownikowy modyfikator obliczeniowy\",\n",
    "    \"mark\": \"znacznik\",\n",
    "    \"obl:cmpr\": \"mianownikowy modyfikator porównawczy\",\n",
    "     \"iobj\": \"\",\n",
    "    \"expl:pv\": \"\",\n",
    "    \"csubj\": \"\",\n",
    "    \"xcomp\":\"\",\n",
    "    \"obj\":\"\",\n",
    "}\n",
    "\n",
    "# Define the column headers for the CSV file\n",
    "headers = [\"Token\", \"Dependency Label (Polish)\", \"Dependency Label (English)\"]\n",
    "\n",
    "# Open a new CSV file for writing\n",
    "with open(\"relacje_syntaktyczne.csv\", \"w\") as csv_file:\n",
    "    # Create a CSV writer\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    # Write the headers to the CSV file\n",
    "    writer.writerow(headers)\n",
    "\n",
    "    # Tokenize the text and split it into sentences\n",
    "    doc = nlp(text)\n",
    "\n",
    "    # Iterate over the sentences and print the dependency parse for each sentence\n",
    "    for sent in doc.sents:\n",
    "        # Iterate over the tokens in the sentence\n",
    "        for token in sent:\n",
    "            # Look up the Polish translation of the dependency label and print it\n",
    "            # along with the token and the English label\n",
    "            row = [token.text, dep_labels[token.dep_], token.dep_]\n",
    "            writer.writerow(row)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c272e29c",
   "metadata": {},
   "source": [
    "##Zapis do PDF grafów z relacjami syntaktycznymi. Nie działa. Tylko wyświelta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10aa063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the spacy, reportlab, and IPython modules\n",
    "import spacy\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.pdfgen.canvas import Canvas # Import the Canvas class from the reportlab.pdfgen.canvas module\n",
    "from IPython import display\n",
    "\n",
    "# Load the Polish language model\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "\n",
    "# Define a sample text\n",
    "text = \"Warszawa to dla mnie galerie, muzea, ludzie, energia, ale też hałas, tłok, korki. Nie jest tu może jak w Berlinie, ale lepiej niż w Gdańsku. Podoba mi się, że ludzie próbują zmieniać to miasto, organizują się sąsiedzi, społeczności. Jest to Babilon, ale jednak uczy funkcjonowania z innymi. \"\n",
    "\n",
    "# Tokenize the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Initialize a counter variable\n",
    "i = 1\n",
    "\n",
    "# Iterate over the sentences in the document\n",
    "for sent in doc.sents:\n",
    "    # Render the dependency parse of the sentence using the \"dep\" style\n",
    "    image = displacy.render(sent, style=\"dep\", options={\"compact\": True, \"bg\": \"#ffffff\", \"color\": \"#000000\"})\n",
    "\n",
    "    # Skip to the next sentence if the image is None\n",
    "    if image is None:\n",
    "        continue\n",
    "\n",
    "    # Create a new PDF document\n",
    "    pdf = Canvas(f\"dep_parse_{i}.pdf\", pagesize=A4) # Use the Canvas class to create the canvas object\n",
    "\n",
    "    # Draw the image on the PDF document\n",
    "    pdf.drawInlineImage(image, 0, 0, A4[0], A4[1]) # Use the drawInlineImage method to draw the image on the PDF document\n",
    "\n",
    "    # Save the PDF document\n",
    "    pdf.save()\n",
    "\n",
    "    # Display the output inline in the notebook\n",
    "    #display.Image(image)\n",
    "\n",
    "    # Increment the counter variable\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b898819",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the spacy, reportlab, and IPython modules\n",
    "import spacy\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.pdfgen.canvas import Canvas # Import the Canvas class from the reportlab.pdfgen.canvas module\n",
    "from IPython import display\n",
    "\n",
    "# Load the Polish language model\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "\n",
    "# Define a sample text\n",
    "text = \"Warszawa to dla mnie galerie, muzea, ludzie, energia, ale też hałas, tłok, korki. Nie jest tu może jak w Berlinie, ale lepiej niż w Gdańsku. Podoba mi się, że ludzie próbują zmieniać to miasto, organizują się sąsiedzi, społeczności. Jest to Babilon, ale jednak uczy funkcjonowania z innymi. \"\n",
    "\n",
    "# Tokenize the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Initialize a counter variable\n",
    "i = 1\n",
    "\n",
    "# Iterate over the sentences in the document\n",
    "for sent in doc.sents:\n",
    "    # Render the dependency parse of the sentence using the \"dep\" style\n",
    "    image = displacy.render(sent, style=\"dep\", options={\"compact\": True, \"bg\": \"#ffffff\", \"color\": \"#000000\"})\n",
    "\n",
    "    # Skip to the next sentence if the image is None\n",
    "    if image is None:\n",
    "        continue\n",
    "\n",
    "    # Create a new PDF document\n",
    "    pdf = Canvas(f\"dep_parse_{i}.pdf\", pagesize=A4) # Use the Canvas class to create the canvas object\n",
    "\n",
    "    # Draw the image on the PDF document\n",
    "    pdf.drawInlineImage(image, 0, 0, A4[0], A4[1]) # Use the drawInlineImage method to draw the image on the PDF document\n",
    "\n",
    "    # Finish the current page\n",
    "    pdf.showPage()\n",
    "\n",
    "    # Save the PDF document\n",
    "    pdf.save()\n",
    "\n",
    "    # Display the output inline in the notebook\n",
    "    #display.Image(image)\n",
    "\n",
    "    # Increment the counter variable\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25045821",
   "metadata": {},
   "source": [
    "##Pokazuje grafy na stronie. Można je później zapisać. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdac2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the spacy and IPython modules\n",
    "import spacy\n",
    "from IPython import display\n",
    "\n",
    "# Load the Polish language model\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "\n",
    "# Define a sample text\n",
    "text = \"Warszawa to dla mnie galerie, muzea, ludzie, energia, ale też hałas, tłok, korki. Nie jest tu może jak w Berlinie, ale lepiej niż w Gdańsku. Podoba mi się, że ludzie próbują zmieniać to miasto, organizują się sąsiedzi, społeczności. Jest to Babilon, ale jednak uczy funkcjonowania z innymi. \"\n",
    "\n",
    "# Tokenize the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Serve the dependency parse diagrams as HTML\n",
    "displacy.serve(doc, style=\"dep\", options={\"compact\": True, \"bg\": \"#ffffff\", \"color\": \"#000000\",\"line_width\": 300})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb64e79",
   "metadata": {},
   "source": [
    "Tworzy Html z grafów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba37087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the spacy module\n",
    "import spacy\n",
    "from IPython import display\n",
    "from spacy import displacy # Import the displacy module from the spacy library\n",
    "\n",
    "# Load the Polish language model\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "\n",
    "# Define a sample text\n",
    "text = \"Warszawa to dla mnie galerie, muzea, ludzie, energia, ale też hałas, tłok, korki. Nie jest tu może jak w Berlinie, ale lepiej niż w Gdańsku. Podoba mi się, że ludzie próbują zmieniać to miasto, organizują się sąsiedzi, społeczności. Jest to Babilon, ale jednak uczy funkcjonowania z innymi. \"\n",
    "\n",
    "# Tokenize the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Iterate over the sentences in the document\n",
    "for sent in doc.sents:\n",
    "    # Render the dependency parse of the sentence using the \"dep\" style\n",
    "    html = displacy.render(sent, style=\"dep\", options={\"compact\": True, \"bg\": \"#ffffff\", \"color\": \"#000000\", \"line_width\": 300})\n",
    "    # Display the rendered HTML\n",
    "    display.display(display.HTML(html))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b708169e",
   "metadata": {},
   "source": [
    "Otwiera stronę internetową. Można wybrać port na której się odpala. http://0.0.0.0:5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ece8073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the spacy and IPython modules\n",
    "import spacy\n",
    "from IPython import display\n",
    "\n",
    "# Load the Polish language model\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "\n",
    "# Define a sample text\n",
    "text = \"Warszawa to dla mnie galerie, muzea, ludzie, energia, ale też hałas, tłok, korki. Nie jest tu może jak w Berlinie, ale lepiej niż w Gdańsku. Podoba mi się, że ludzie próbują zmieniać to miasto, organizują się sąsiedzi, społeczności. Jest to Babilon, ale jednak uczy funkcjonowania z innymi. \"\n",
    "\n",
    "# Tokenize the text\n",
    "doc = nlp(text)\n",
    "\n",
    "# Serve the dependency parse diagrams as HTML\n",
    "displacy.serve(doc, style=\"dep\", options={\"compact\": True, \"bg\": \"#ffffff\", \"color\": \"#000000\", \"line_width\": 300, \"port\": 5000})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9830b02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
